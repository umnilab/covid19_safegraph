{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from tqdm.notebook import tqdm\n",
    "from importlib import reload\n",
    "from glob import glob\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import covid_commons as g\n",
    "from covid_commons import peek\n",
    "g = reload(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load city data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load the city information\n",
    "cities = g.load_cities()\n",
    "\n",
    "# create new variables for Chicago & NYC & update the cities list\n",
    "nyc = cities['nyc']\n",
    "chi = cities['chi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "il = g.City('il', {\n",
    "    'name': 'Illinois',\n",
    "    'events': {},\n",
    "    'counties': {x[-3:]: [17, int(x[-3:])] for x in\n",
    "                 glob(g.DATA_DIR+'/county_wise/17/*')}\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nyc.name = 'NYC'\n",
    "nyc.full_name = 'New York City'\n",
    "chi.full_name = 'Chicago'\n",
    "nyc.color = 'dodgerblue'\n",
    "chi.color = 'blueviolet'\n",
    "il.full_name = 'Illinois'\n",
    "il.color = 'tomato'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# cities = [chi, nyc]\n",
    "cities = [nyc, il]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pickled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for c in tqdm(cities):\n",
    "    g.load_city_data(c, exclude=['pat_od'], pat_vars=['dwells'])\n",
    "    \n",
    "    # combine patterns with dwell bin visits\n",
    "    c.pat = pd.concat([c.pat, c.dwells], axis=1).drop(columns=['poi_cbg'])\n",
    "    del c.dwells\n",
    "    \n",
    "    # add the exposure data to the patterns table & then delete it\n",
    "    c.exp_daily = c.exp.copy()\n",
    "    c.exp = (c.exp.reset_index()\n",
    "             .assign(week = lambda x:\n",
    "                     g.date2int(g.get_week(g.int2date(x['date']))))\n",
    "             .drop(columns=['date'])\n",
    "             .assign(tot_cei = lambda x: x['cei']*x['exp_visits'])\n",
    "             .groupby(['poi_id', 'week'])\n",
    "             [['exp_visits', 'tot_cei']].sum()\n",
    "             .assign(cei = lambda x: x['tot_cei']/x['exp_visits'])\n",
    "             .astype({'cei': np.float32, 'tot_cei': np.float32,\n",
    "                      'exp_visits': np.int32}))\n",
    "    c.pat = c.pat.merge(c.exp, on=('poi_id', 'week'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cases/deaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NYC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def set_nyc_cases():\n",
    "    \"\"\"\n",
    "    For NYC, the cases data is broken into two parts.\n",
    "    1. The first part contains values before May 18 and are retrieved from an\n",
    "    independent Github repo. This table has fewer variables.\n",
    "    2. The second part contains values on and after May 19 and are collected\n",
    "    from an official source of the government of NYC. This table has more\n",
    "    variables like testing rate.\n",
    "    These two sources have to be combined appropriately but values of one\n",
    "    particular day (April 26) have to be adjusted because of miscalculation.\n",
    "    \"\"\"\n",
    "    ## before May 18\n",
    "    # first get the raw data\n",
    "    cases_old = (\n",
    "        pd.read_csv(g.IO['nyc_cases_old'])\n",
    "        .assign(date = lambda x: g.str2date(x['timestamp'].str.slice(0, 10)))\n",
    "        .drop(columns=['timestamp'])\n",
    "        .rename(columns={'zcta': 'zip', 'positive': 'cum_cases',\n",
    "                         'total': 'cum_tests'})\n",
    "        .query('zip != 99999') # this zip does not exist in reality\n",
    "        .dropna()\n",
    "        .astype({'zip': int})\n",
    "    )\n",
    "    # 26 Apr is an outlier with a sudden increase in cum. cases with a decline\n",
    "    # in cum. cases on 27 Apr, so make 26 Apr values avg. of 25 & 27 Apr\n",
    "    # similarly, 6th Apr data is unavailable, so use avg. of 5 & 7 Apr\n",
    "    temp = pd.DataFrame()\n",
    "    for zip_, df in cases_old.groupby('zip'):\n",
    "        df = df.set_index('date')\n",
    "        df.loc[g.str2date('2020-04-06')] = np.nan\n",
    "        for date in g.str2date(pd.Series(['2020-04-06', '2020-04-26'])):\n",
    "            prev = df.loc[date - pd.DateOffset(1)]\n",
    "            next_ = df.loc[date + pd.DateOffset(1)]\n",
    "            df.loc[date] = 0.5*(prev + next_)\n",
    "        temp = temp.append(df.reset_index(), ignore_index=True)\n",
    "    cases_old = temp.copy().sort_values('date')\n",
    "\n",
    "    \n",
    "    # combine these two units\n",
    "    cases_old = (\n",
    "        cases_old.merge(\n",
    "            cases_old\n",
    "            .groupby('zip')\n",
    "            .apply(lambda x: x.set_index('date').diff())\n",
    "            .rename(columns={'cum_cases': 'new_cases',\n",
    "                             'cum_tests': 'new_tests'})\n",
    "            .dropna()\n",
    "            .astype({'new_cases': int, 'new_tests': int})\n",
    "            .drop(columns=['zip']),\n",
    "            on=('zip', 'date'))\n",
    "        .dropna()\n",
    "        .set_index(['zip', 'date'])\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    # after May 18\n",
    "    cases_new = (\n",
    "        pd.read_csv(g.IO['nyc_cases_new'])\n",
    "        .rename(columns=lambda x: x.lower().replace('covid_', ''))\n",
    "        .rename(columns={'modified_zcta': 'zip', 'pop_denominator': 'popu',\n",
    "                         'percent_positive': 'pct_positive',\n",
    "                         'total_tests': 'cum_tests', 'case_count': 'cum_cases',\n",
    "                         'death_count': 'cum_deaths'})\n",
    "        .drop(columns=['neighborhood_name'])\n",
    "        .assign(date = lambda x: g.str2date(x['date']))\n",
    "        .set_index(['zip', 'date'])\n",
    "        .reset_index()\n",
    "        .drop_duplicates(subset=['zip', 'date'])\n",
    "    )\n",
    "    cases_new = (\n",
    "        cases_new.merge(\n",
    "            cases_new\n",
    "            .sort_values('date')\n",
    "            [['zip', 'date', 'cum_cases', 'cum_deaths', 'cum_tests']]\n",
    "            .groupby('zip')\n",
    "            .apply(lambda x: x.set_index('date').diff())\n",
    "            .rename(columns=lambda x: x.replace('cum', 'new'))\n",
    "            .fillna(0)\n",
    "            .drop(columns=['zip'])\n",
    "            .reset_index(),\n",
    "            on=('zip', 'date')\n",
    "        )\n",
    "    )\n",
    "    # combine the old and new cases\n",
    "    cases = (\n",
    "        cases_old.append(cases_new[['zip', 'date', 'cum_cases', 'cum_tests',\n",
    "                                    'new_cases', 'new_tests']])\n",
    "            .sort_values(['zip', 'date'])\n",
    "#             .astype({'cum_cases': int, 'cum_tests': int})\n",
    "            .assign(week = lambda x: g.get_week(x['date']))\n",
    "    )\n",
    "    # set these as object members\n",
    "    nyc.cases_old = cases_old\n",
    "    nyc.cases_new = cases_new\n",
    "    nyc.cases = cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "set_nyc_cases()\n",
    "peek(nyc.cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nyc.cases.groupby('date').new_cases.sum().plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set important zip codes\n",
    "These zip codes are the ones which contain the case data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nyc.imp_zips = pd.Series(nyc.cases['zip'].unique(), name='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illinois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "il.cases = (pd.read_csv(g.IO['il_cases'])\n",
    "            .rename(columns={'zipcode': 'zip'})\n",
    "            .assign(date = lambda x: g.str2date(x['date']))\n",
    "            .rename(columns=lambda x: x.replace('confirmed_', 'cum_')\n",
    "                    .replace('total_tested', 'tests'))\n",
    "            .rename(columns={'cum_cases_change': 'new_cases',\n",
    "                             'tests_change': 'new_tests',\n",
    "                             'tests': 'cum_tests'})\n",
    "            .set_index(['zip', 'date'])\n",
    "            .apply(lambda x: np.clip(x, 0, np.inf))\n",
    "            .reset_index())\n",
    "peek(il.cases, top=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "il.cases.groupby('date').new_cases.sum().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "il.imp_zips = pd.Series(il.cases['zip'].unique(), name='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chicago"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "chi.case_cols = {\n",
    "    'ZIP Code':                'zip',\n",
    "    'Week Number':             'wk_num',\n",
    "    'Week Start':              'wk_start',\n",
    "    'Week End':                'wk_end',\n",
    "    'Cases - Weekly':          'wk_cases',\n",
    "    'Cases - Cumulative':      'cum_cases',\n",
    "    'Case Rate - Weekly':      'wk_case_rate',\n",
    "    'Case Rate - Cumulative':  'cum_case_rate',\n",
    "    'Tests - Weekly':          'wk_tests',\n",
    "    'Tests - Cumulative':      'cum_tests',\n",
    "    'Test Rate - Weekly':      'wk_test_rate',\n",
    "    'Test Rate - Cumulative':  'cum_test_rate',\n",
    "    'Percent Tested Positive - Weekly':       'wk_pct_pos',\n",
    "    'Percent Tested Positive - Cumulative':   'cum_pct_pos',\n",
    "    'Deaths - Weekly':         'wk_deaths',\n",
    "    'Deaths - Cumulative':     'cum_deaths',\n",
    "    'Death Rate - Weekly':     'wk_death_rate',\n",
    "    'Death Rate - Cumulative': 'cum_death_rate',\n",
    "    'Population':              'popu',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "chi.cases = (pd.read_csv(g.IO['chi_cases'])\n",
    "             .rename(columns=chi.case_cols)\n",
    "             .query('zip != \"Unknown\"')\n",
    "             [chi.case_cols.values()]\n",
    "             .assign(wk_start = lambda x: g.str2date(x['wk_start'], '%m/%d/%Y'),\n",
    "                     wk_end = lambda x: g.str2date(x['wk_end'], '%m/%d/%Y'))\n",
    "             .assign(week = lambda x: x['wk_start'] + pd.DateOffset(days=1))\n",
    "             .astype({'zip': int, 'wk_num': int})\n",
    "             .sort_values(['wk_end', 'zip'])\n",
    "             .set_index(['zip', 'week'])\n",
    "             .reset_index())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "peek(chi.cases, top=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "chi.zips = (g.map_cbg_zip(il.acs.index)\n",
    "            .assign(cnty = lambda x: (x['cbg']//1e7).astype(int))\n",
    "            .pipe(lambda x: x[x['cnty'].isin([x[0]*1000+x[1] for x in\n",
    "                                              chi.counties.values()])])\n",
    "            ['zip'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "chi.pois = il.pois[il.pois['zip'].isin(chi.zips)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "chi.cases = il.cases[il.cases['zip'].isin(chi.zips)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "chi.exp_daily = (il.exp_daily.reset_index()\n",
    "                 .merge(il.pois['cbg'], on='poi_id')\n",
    "                 .assign(cnty=lambda x: x['cbg']//1e7)\n",
    "                 .pipe(lambda x: x[x['cnty'].isin([x[0]*1000+x[1] for x in\n",
    "                                                   chi.counties.values()])])\n",
    "                 .set_index(['date', 'poi_id'])\n",
    "                 .drop(columns=['cbg', 'cnty']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "chi.imp_zips = pd.Series(chi.cases['zip'].unique(), name='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set important zip codes\n",
    "These zip codes are the ones which contain the case data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "chi.imp_zips = pd.Series(chi.cases['zip'].unique(), name='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zip code data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### National"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "zip2tract = g.load_all_zips()\n",
    "peek(zip2tract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "zips_shp = (gp.read_file(g.IO['zips_shp'])\n",
    "            .rename(columns={'ZCTA5CE10': 'zip'})\n",
    "            .astype({'zip': np.int32}))\n",
    "peek(zips_shp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zip shapefile & mapping to CBG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nyc.shp_zip = (gp.read_file(glob(nyc.dir+'/shapefile_zip/*.shp')[0])\n",
    "               .rename(columns={'postalCode': 'zip'})\n",
    "               [['zip', 'geometry']]\n",
    "               .astype({'zip': np.int32}))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "chi.shp_zip = (gp.read_file(glob(chi.dir+'/shapefile_zip/*.shp')[0])\n",
    "               [['zip', 'geometry']]\n",
    "               .astype({'zip': np.int32}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "il.shp_zip = (zips_shp.merge(zip2tract.query('state == 17')['zip'], on='zip')\n",
    "              [['zip', 'geometry']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "chi.shp_zip = il.shp_zip.pipe(lambda x: x[x['zip'].isin(chi.zips)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the zip-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_acs_by_zip(city):\n",
    "    \"\"\"\n",
    "    Aggregate relevant census CBG-level variables over zip codes.\n",
    "    It's important to use the correct measures & aggregation technique here.\n",
    "    \"\"\"\n",
    "    # get the mapping between CBG & zip code\n",
    "    zip2cbg = g.map_cbg_zip(city.acs.index, zip2tract)\n",
    "    # remove 0 population CBGs\n",
    "    acs = city.acs.query('tot_pop > 0')\n",
    "    grp = acs.merge(zip2cbg, on='cbg').groupby('zip')\n",
    "    x = grp[['tot_pop', 'tot_hh', 'tot_income', 'tot_hh_income']].sum().astype(int)\n",
    "    x['avg_income'] = x['tot_income']/x['tot_pop']\n",
    "    x['avg_hh_income'] = x['tot_hh_income']/x['tot_hh']\n",
    "    x['inc_bin'] = g.get_inc_classes(x['avg_income'])\n",
    "    x['hh_inc_bin'] = g.get_inc_classes(x['avg_hh_income'])\n",
    "    x['inc_q'] = x['inc_bin'].cat.codes + 1\n",
    "    x['hh_inc_q'] = x['hh_inc_bin'].cat.codes + 1\n",
    "    for var in g.VUL_VARS:\n",
    "        x[var] = grp.apply(g.wtd_avg, val=var, wt='tot_pop')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for c in cities:\n",
    "    c.acs_zip = get_acs_by_zip(c)\n",
    "peek(nyc.acs_zip, top=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "chi.acs_zip = il.acs_zip.pipe(lambda x: x[x.index.isin(chi.zips)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot((nyc.acs_zip\n",
    "              [['avg_hh_income'] + g.VUL_VARS]),\n",
    "              diag_kind='kde', height=1.5, plot_kws={'s': 10});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot((chi.acs_zip\n",
    "              [['avg_hh_income'] + g.VUL_VARS]),\n",
    "              diag_kind='kde', height=1.5, plot_kws={'s': 10});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter in-hospital POIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read all U.S. POIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "POIS = g.load_all_pois().merge(pd.concat([c.imp_zips for c in cities]))\n",
    "peek(POIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ALL_NAICS = g.load_all_naics()\n",
    "peek(ALL_NAICS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove in-hospital POIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "POIS.merge(nyc.pois['naics'], on='poi_id')\n",
    "[['poi_id', 'parent_poi_id']]\n",
    ".rename(columns={'poi_id': 'child_id', 'parent_poi_id': 'parent_id'})\n",
    ".merge(nyc.pois['naics'], left_on='parent_id', right_index=True)\n",
    ".rename(columns={'naics': 'parent_naics'})\n",
    ".astype({'parent_id': np.int32})\n",
    ".merge(ALL_NAICS, left_on='parent_naics', right_on='naics')\n",
    ".groupby(['naics', 'naics_title']).size().sort_values(ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def filter_in_naics_pois(city, all_pois=POIS, filt_naics=[622110]):\n",
    "    \"\"\"\n",
    "    Get the list of POIs that lie within another POI which lies in a given\n",
    "    list of NAICS codes. For the analysis here, only in-hospital (#622110)\n",
    "    POIs are excluded.\n",
    "    \"\"\"\n",
    "    # get the mapping between \n",
    "    child2parent = (\n",
    "        all_pois.merge(city.pois['naics'], on='poi_id')\n",
    "        [['poi_id', 'parent_poi_id']]\n",
    "        .rename(columns={'poi_id': 'child_id', 'parent_poi_id': 'parent_id'})\n",
    "        .merge(city.pois['naics'], left_on='parent_id', right_index=True)\n",
    "        .rename(columns={'naics': 'parent_naics'})\n",
    "        .astype({'parent_id': np.int32})\n",
    "    )\n",
    "    # filter the POIs whose parent has NAICS in one of the filt_naics\n",
    "    if filt_naics is not None:\n",
    "        child2parent = (child2parent.pipe(lambda x: x[\n",
    "            x['parent_naics'].isin(filt_naics)]))\n",
    "    \n",
    "    return child2parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for c in cities:\n",
    "    c.in_hosp_pois = (filter_in_naics_pois(c, filt_naics=[622110])\n",
    "                      ['child_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nyc.pois.loc[nyc.in_hosp_pois].merge(g.IMP_NAICS, on='naics').groupby('naics').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mobility processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calc. total dwell time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# add the columns for visits & total dwell times with 4 and 5 bins\n",
    "for c in cities:\n",
    "    if not 'visits5' in c.pat.columns:\n",
    "        c.pat['visits5'] = c.pat['visits']\n",
    "        del c.pat['visits']\n",
    "    c.pat['visits4'] = c.pat[g.DWELL_BINS['names'][:4]].sum(1)\n",
    "    c.pat['tot_dwell5'] = (c.pat[g.DWELL_BINS['names']].values @\n",
    "                           g.DWELL_BINS['avg'])\n",
    "    c.pat['tot_dwell4'] = (c.pat[g.DWELL_BINS['names'][:4]].values @\n",
    "                           g.DWELL_BINS['avg'][:4])\n",
    "    c.pat = c.pat.astype({'visits4': np.int32, 'visits5': np.int32,\n",
    "                          'tot_dwell4': np.int32, 'tot_dwell5': np.int32})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join pat_od with pat & expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def join_pat_pat_od(city, inc_bin_var='hh_inc_bin'):\n",
    "    \"\"\"\n",
    "    Join the POI patterns data with the patterns OD matrix for faster\n",
    "    downstream analysis.\n",
    "    \"\"\"\n",
    "    pat = (city.pat\n",
    "           .rename(columns={'visitors': 'poi_visitors', 'zip': 'poi_zip'})\n",
    "           .drop(columns=['cnty']))\n",
    "    od_zip = (city.od_zip\n",
    "              .rename(columns={'date': 'week', 'zip': 'home_zip',\n",
    "                               'visitors': 'home_visitors'}))\n",
    "    joined = pat.merge(od_zip, on=('row_id', 'week')).drop(columns='row_id')\n",
    "    return joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for c in tqdm(cities):\n",
    "    c.odX = join_pat_pat_od(c).rename(columns={'zip': 'poi_zip'})\n",
    "peek(nyc.odX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get indices for quick filtering odX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for c in tqdm(cities):\n",
    "    print(c.name)\n",
    "    # mark rows True whose POIs lie in zip codes with case data\n",
    "    c.odX['imp_zip'] = False\n",
    "    c.odX.loc[(c.odX['poi_zip'].isin(c.imp_zips)) &\n",
    "              (c.odX['home_zip'].isin(c.imp_zips)), 'imp_zip'] = True\n",
    "    \n",
    "    # mark rows whose POIs lie within hospital\n",
    "    c.odX['out_hosp'] = True\n",
    "    c.odX.loc[c.odX['poi_id'].isin(c.in_hosp_pois), 'out_hosp'] = False\n",
    "    \n",
    "    # mark rows whose POIs lie in imp_zips & are NOT within hospitals\n",
    "    c.odX['imp_zip_out_hosp'] = False\n",
    "    c.odX.loc[(c.odX['imp_zip']==True) & (c.odX['out_hosp']==True),\n",
    "              'imp_zip_out_hosp'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%time chi.odX = il.odX[(il.odX['poi_zip'].isin(chi.zips)) & (il.odX['home_zip'].isin(chi.zips))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the zips having case data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Filter the relevant data of a city pertaining to only the zip areas where\n",
    "health data is available. This is a crucial step because it may greatly\n",
    "influence the downstream analysis. This step may be skipped to assess the\n",
    "difference in results between important and all zip codes.\n",
    "Also optionally skip POIs that lie inside hospitals.\n",
    "\"\"\"\n",
    "def get_pois(city, imp_zips=False, exclude_in_hosp=True):\n",
    "    if not imp_zips:\n",
    "        pois = city.pois\n",
    "    else:\n",
    "        pois = city.pois.reset_index().merge(city.imp_zips).set_index('poi_id')\n",
    "    if exclude_in_hosp:\n",
    "        pois = pois[~pois.index.isin(city.in_hosp_pois)]\n",
    "    return pois\n",
    "\n",
    "def get_acs_zip(city, imp_zips=False):\n",
    "    if not imp_zips:\n",
    "        return city.acs_zip\n",
    "    else:\n",
    "        acs = city.acs_zip.merge(city.imp_zips, on='zip')\n",
    "        acs['inc_bin'] = pd.qcut(acs['avg_income'], g.INC_NBINS)\n",
    "        acs['hh_inc_bin'] = pd.qcut(acs['avg_hh_income'], g.INC_NBINS)\n",
    "        acs['inc_q'] = acs['inc_bin'].cat.codes + 1\n",
    "        acs['hh_inc_q'] = acs['hh_inc_bin'].cat.codes + 1\n",
    "        acs = acs.set_index('zip')\n",
    "        return acs\n",
    "\n",
    "def get_pat(city, imp_zips=False, out_hosp=True):\n",
    "    if not imp_zips:\n",
    "        pat = city.pat\n",
    "    else:\n",
    "        pat = city.pat.merge(city.imp_zips, on='zip')\n",
    "    if out_hosp:\n",
    "        pat = pat[~pat['poi_id'].isin(city.in_hosp_pois)]\n",
    "    return pat\n",
    "\n",
    "def get_od_zip(city, imp_zips=False):\n",
    "    if not imp_zips:\n",
    "        return city.od_zip\n",
    "    return city.od_zip.merge(city.imp_zips, on='zip')\n",
    "    \n",
    "def get_odX(city, imp_zips=False, out_hosp=True):\n",
    "    odX = city.odX\n",
    "    if imp_zips and out_hosp:\n",
    "        odX = odX[odX['imp_zip_out_hosp'] == True]\n",
    "    else:\n",
    "        if imp_zips:\n",
    "            odX = odX[odX['imp_zip'] == True]\n",
    "        if out_hosp:\n",
    "            odX = odX[odX['out_hosp'] == True]\n",
    "    return odX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "peek(get_acs_zip(nyc, True), top=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "peek(get_pat(nyc, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "peek(get_od_zip(nyc, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%time peek(get_odX(nyc, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate comparison of pat with expanded pat_od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def compare_odx_with_pat(city, imp_zips=True):\n",
    "    \"\"\"\n",
    "    Compare the aggregate level measures of a city's POI patterns table (where\n",
    "    each row is (POI, week)) with the pat OD extended table (odx) (each row is\n",
    "    (POI, week, home zip)).\n",
    "    \"\"\"\n",
    "    print('Comparing no. of items of weeks, POIs & week-POIs in pat and odx tables')\n",
    "    for grp_var in ['week', 'poi_id', ['week', 'poi_id']]:\n",
    "        print(f'pat: {grp_var}', get_pat(city, imp_zips).groupby(grp_var).size().size)\n",
    "        print(f'odx: {grp_var}', get_odX(city, imp_zips).groupby(grp_var).size().size)\n",
    "    \n",
    "compare_odx_with_pat(nyc, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get top specific industry dwellers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_top_dweller_pois(city, week, naics, all_pois=POIS, out_hosp=True):\n",
    "    pat = (get_pat(city, imp_zips=True, out_hosp=out_hosp)\n",
    "           .query(f'naics == {naics}')\n",
    "           .query('week == {}'.format(week[2:].replace('-', '')))\n",
    "           [['poi_id'] + g.DWELL_BINS['names'] + ['visits5', 'tot_dwell5']]\n",
    "           .assign(avg_dwell5 = lambda x: x['tot_dwell5']/x['visits5'])\n",
    "          )\n",
    "    pat = (all_pois.merge(pat, on='poi_id')\n",
    "           .sort_values('tot_dwell5', ascending=False)\n",
    "           .reset_index(drop=True))\n",
    "        \n",
    "    return pat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(get_top_dweller_pois(nyc, '2020-03-23', 722513, out_hosp=False).head(10)\n",
    " [['location_name', 'city', 'tot_dwell5', 'parent_poi_id'] + g.DWELL_BINS['names']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zips map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_map_zips(city, cntys=None, cbgs=True, epsg=4326, figsize=(10, 10)):\n",
    "    \"\"\"\n",
    "    Plot the map of the zip areas and see how they are different from CBGs\n",
    "    (overlaps). Use either all zips or only the ones with the case data\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.axis('off')\n",
    "    zip_df = city.shp_zip.copy()\n",
    "    if cntys is not None:\n",
    "        cnty_df = (city.shp_cnty.astype({'COUNTYFP': int})\n",
    "                   .pipe(lambda x: x[x['COUNTYFP'].isin(cntys)]))\n",
    "        cbg_df = (city.shp_cbg.astype({'countyfp': int})\n",
    "                  .pipe(lambda x: x[x['countyfp'].isin(cntys)]))\n",
    "    else:\n",
    "        cnty_df = city.shp_cnty\n",
    "        cbg_df = city.shp_cbg\n",
    "    zip_df.plot(ax=ax, facecolor='none', edgecolor='black', linewidth=1.5)\n",
    "    cnty_df.plot(ax=ax, facecolor='none', edgecolor='orange', linewidth=1.5)\n",
    "    if cbgs:\n",
    "        cbg_df.plot(ax=ax, facecolor='none', edgecolor='blue', linewidth=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_map_zips(nyc, cntys=[61, 5, 81, 47, 85])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_map_zips(chi, cntys=[31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_map_zips(il, cbgs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_map_cases(city, cntys=None, epsg=4326, figsize=(10, 10)):\n",
    "    \"\"\"\n",
    "    Plot the map of cases by zip code.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.axis('off')\n",
    "    zip_df = city.shp_zip.copy()\n",
    "    if cntys is not None:\n",
    "        cnty_df = (city.shp_cnty.astype({'COUNTYFP': int})\n",
    "                   .pipe(lambda x: x[x['COUNTYFP'].isin(cntys)]))\n",
    "        cbg_df = (city.shp_cbg.astype({'countyfp': int})\n",
    "                  .pipe(lambda x: x[x['countyfp'].isin(cntys)]))\n",
    "    else:\n",
    "        cnty_df = city.shp_cnty\n",
    "        cbg_df = city.shp_cbg\n",
    "    zip_df.plot(ax=ax, facecolor='none', edgecolor='black', linewidth=1.5)\n",
    "    cnty_df.plot(ax=ax, facecolor='none', edgecolor='orange', linewidth=1.5)\n",
    "    cbg_df.plot(ax=ax, facecolor='none', edgecolor='blue', linewidth=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population composition by income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_pie_by_inc_class(city, var='tot_pop', imp_zips=True, inc_bin_var='hh_inc_bin'):\n",
    "    \"\"\"\n",
    "    Plot the pie chart of an extensive measure by city's income classes.\n",
    "    \"\"\"\n",
    "    # get the zip-level census data\n",
    "    acs = get_acs_zip(city, imp_zips)\n",
    "    \n",
    "    df = acs.groupby(inc_bin_var)[var].sum()\n",
    "    colors = sns.color_palette(g.CMAPS['income_classes'], g.INC_NBINS)\n",
    "    labels = [f'{x.left/1e3:.0f}k - {x.right/1e3:.0f}k' for x in df.index.tolist()]\n",
    "    df.plot(kind='pie', colors=colors, labels=labels,\n",
    "            autopct='%.1f%%', startangle=90)\n",
    "    plt.ylabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_pie_by_inc_class(nyc, var='tot_pop', inc_bin_var='inc_bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_pie_by_inc_class(nyc, var='tot_pop', inc_bin_var='hh_inc_bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_pie_by_inc_class(nyc, var='tot_hh', inc_bin_var='hh_inc_bin')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_pie_by_inc_class(chi, var='tot_hh', inc_bin_var='hh_inc_bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_pie_by_inc_class(il, var='tot_pop', inc_bin_var='inc_bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_pie_by_inc_class(il, var='tot_pop', inc_bin_var='hh_inc_bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_pie_by_inc_class(il, var='tot_hh', inc_bin_var='hh_inc_bin')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_pie_by_inc_class(chi, var='tot_hh', inc_bin_var='hh_inc_bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_popu_by_inc_class(city, var='tot_pop', imp_zips=True,\n",
    "                           inc_bin_q='hh_inc_q', dpi=70):\n",
    "    # get the zip-level census data\n",
    "    acs = get_acs_zip(city, imp_zips)\n",
    "    vals = acs.groupby(inc_bin_q)[var].sum()/1e3\n",
    "    vals = pd.concat([vals, (vals/vals.sum()).rename('proportion')], axis=1)\n",
    "    inc_q_map = {1:2,2:4,3:3,4:1,5:5}\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(figsize=(2.8, 4.1), dpi=dpi)\n",
    "    plt.barh(vals.index, vals[var], color=g.COLORS['income_classes5'],\n",
    "             height=0.55)\n",
    "    plt.ylabel('Income class', fontsize=20)\n",
    "    plt.yticks(fontsize=16)\n",
    "#     plt.title('Population income\\n distribution', fontsize=18)\n",
    "    plt.xlabel('No. of residents (k)', fontsize=20)\n",
    "    for i, v in enumerate(vals['proportion']):\n",
    "        ax.text(v+100, i+0.9, f'{v*100:.2f}%', color='k', fontsize=13)\n",
    "    return inc_q_map\n",
    "\n",
    "_ = plot_popu_by_inc_class(nyc, dpi=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POI visitors to visits ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_visit_visitor_ratio(city, imp_zips=True):\n",
    "    \"\"\"\n",
    "    Plot the trend of ratio of visits to visitors to POIs of a city.\n",
    "    \"\"\"\n",
    "    ratios = (get_pat(city, imp_zips)\n",
    "              .groupby(['week'])\n",
    "              [['visits5', 'visitors']].sum()\n",
    "              .reset_index()\n",
    "              .assign(ratio = lambda x: x['visits5']/x['visitors'],\n",
    "                      week = lambda x: g.int2date(x['week']))\n",
    "              .set_index('week')['ratio']\n",
    "             )\n",
    "    ratios.plot(marker='o')\n",
    "    plt.title('Ratio of total POI visits to total visitors in '+\n",
    "              city.name)\n",
    "    plt.ylabel('Visits/Visitors')\n",
    "    plt.xlabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_visit_visitor_ratio(nyc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_visit_visitor_ratio(chi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_visit_visitor_ratio(il)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_trend_mob_by_income(dpi=70):\n",
    "    bins = [0, 50, 75, 100, 150, 1000]\n",
    "    inc = (pd.cut((nyc.acs['avg_hh_income']/1e3).dropna(),\n",
    "                  bins)).rename('inc_bin')\n",
    "    res = (get_pat(nyc, True)\n",
    "           .merge(nyc.pois['cbg'], on='poi_id')\n",
    "           .merge(inc, on='cbg')\n",
    "           .assign(inc_q = lambda x: (x['inc_bin'].cat.codes+1).map(_))\n",
    "           .query('inc_q > 0')\n",
    "           .groupby(['inc_q', 'week'])\n",
    "           ['visits5'].sum()\n",
    "           .reset_index()\n",
    "           .assign(week = lambda x: g.int2date(x['week']))\n",
    "           .set_index('week')\n",
    "           .pipe(lambda x: x[(x.index <= g.int2date(200520)) &\n",
    "                             (x.index >= g.int2date(200130))]))\n",
    "    fig, ax = plt.subplots(figsize=(5, 3), dpi=dpi)\n",
    "    colors = g.COLORS['income_classes5']\n",
    "    labels = {i+1: f'\\${bins[i]} - \\${bins[i+1]}k' for i in range(len(bins)-1)}\n",
    "    plt.xticks(pd.date_range('2020-02-03', '2020-05-11', freq='7D'),\n",
    "               rotation=90, fontsize=10)\n",
    "    for i, (inc_q, df) in enumerate(res.groupby('inc_q')):\n",
    "        ax.plot((df['visits5']/1e6).diff()*100, color=colors[i],\n",
    "                marker='.', label=labels[inc_q])\n",
    "    plt.title('Change in weekly visitors in NYC by income class', fontsize=14)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('% change in visitors')\n",
    "    ax.xaxis.set_major_formatter(mpl.dates.DateFormatter('%d %b'))\n",
    "    ax.set_yticks(np.arange(-60, 20, 10))\n",
    "    ax.yaxis.grid(ls='--')\n",
    "    ax.axhline(0, color='grey', lw=0.8)\n",
    "    for evt, date in [('State emergency declared', 200307), ('SAH ordered', 200319)]:\n",
    "        ax.axvline(g.int2date(date), color='grey', ls='--')\n",
    "        ax.text(g.int2date(date), ax.get_ylim()[1], evt, ha='right', va='top',\n",
    "                rotation=90)\n",
    "#     return res\n",
    "plot_trend_mob_by_income(dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_mob_trend(city):\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 4), dpi=70)\n",
    "    ax2 = ax1.twinx()\n",
    "    (city.sd\n",
    "     .assign(tot_time_home = lambda x: x['tot_dev']*x['time_home'])\n",
    "     .groupby('date').sum()\n",
    "     .assign(time_home = lambda x: x['tot_time_home']/x['tot_dev']/24,\n",
    "             prop_home = lambda x: x['dev_home']/x['tot_dev'])\n",
    "     [['time_home', 'prop_home']]\n",
    "     .plot(ax=ax2, color=['orange', 'tomato'])\n",
    "    )\n",
    "    ax2.legend(labels=['% day spent at home', '% devices at home all day'],\n",
    "               loc='center right')\n",
    "    ((city.pat.groupby('week')['visitors'].sum()/1e6)\n",
    "     .reset_index()\n",
    "     .assign(week = lambda x: g.int2date(x['week']))\n",
    "     .set_index('week')\n",
    "     .plot(ax=ax1, label='Visitors')\n",
    "    )\n",
    "    for evt, date in [('State emergency declared', 200307), ('SAH ordered', 200319)]:\n",
    "        ax1.axvline(g.int2date(date), ls='--', color='grey')\n",
    "        ax1.text(g.int2date(date), ax1.get_ylim()[1], evt, color='k',\n",
    "                 ha='right', va='top', rotation=90)\n",
    "    ax1.legend(labels=['Weekly visitors'], loc='upper left')\n",
    "    ax1.set_xlabel('')\n",
    "    ax1.set_ylabel('Weekly visitors (M)')\n",
    "    ax2.set_ylabel('Daily social distancing measures')\n",
    "    plt.title('Variation of 3 mobility metrics in NYC during COVID-19')\n",
    "    \n",
    "plot_mob_trend(nyc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POI visits by income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_poi_vis_by_poi_inc(city, var='visits5', imp_zips=True, plot=False):\n",
    "    \"\"\"\n",
    "    Get the weekly visits or visitors to the POIs totalled by the income class\n",
    "    of the zip code in which the POI lies.\n",
    "    @param var: <str> POI-based measure of mobility (either `poi_visits` or\n",
    "    `poi_visitors`)\n",
    "    @param imp_zip: whether include only the zips with cases data\n",
    "    \"\"\"\n",
    "    # get the expanded zip OD matrix (with POI attrs) & get its income\n",
    "    res = (get_odX(city, imp_zips)\n",
    "           .merge(city.acs_zip['hh_inc_q'], left_on='poi_zip', right_index=True)\n",
    "           .rename(columns={'hh_inc_q': 'poi_inc_q'})\n",
    "           .groupby(['week', 'poi_id', 'poi_inc_q'])\n",
    "           [[var]].first()\n",
    "           .groupby(['week', 'poi_inc_q'])\n",
    "           .sum()\n",
    "           .reset_index()\n",
    "           .assign(week = lambda x: g.int2date(x['week'], fmt='%y%m%d'))\n",
    "           .set_index('week')\n",
    "          )\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots()\n",
    "        colors = sns.color_palette(g.CMAPS['income_classes'], g.INC_NBINS)\n",
    "        for (bin_, df), col in zip(res.groupby('poi_inc_q'), colors):\n",
    "            (df[var]/1e3).plot(ax=ax, color=col, label=f'Q{bin_}')\n",
    "        plt.xlabel('')\n",
    "        ylabel = ''\n",
    "        if var == 'visits5': ylabel = 'Visits (k)'\n",
    "        if var == 'visitors': ylabel = 'Visitors (k)'\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.title(f'Weekly {var} by income quintile\\n' +\n",
    "                  'of POI zip in ' + city.name);\n",
    "        plt.legend()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%time _ = get_poi_vis_by_poi_inc(nyc, plot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%time _ = get_poi_vis_by_poi_inc(nyc, var='poi_visitors', plot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Inference</b>: More people come to richer POIs than poorer POIs."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%time _ = get_poi_vis_by_poi_inc(il, plot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Inference</b>: More people come to richer POIs than poorer POIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Home visitors by income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_poi_vis_by_home_inc(city, imp_zips=True, plot=False):\n",
    "    \"\"\"\n",
    "    Get the weekly visits to the POIs totalled by the income class of the zip\n",
    "    code in which the POI lies.\n",
    "    \"\"\"\n",
    "    res = (get_odX(city, imp_zips)\n",
    "           .merge(city.acs_zip['hh_inc_q'].rename('home_inc_q'),\n",
    "                  left_on='home_zip', right_index=True)\n",
    "           .groupby(['week', 'home_inc_q'])\n",
    "           ['home_visitors'].sum()\n",
    "           .reset_index()\n",
    "           .assign(week = lambda x: g.int2date(x['week'], fmt='%y%m%d'))\n",
    "           .set_index('week')\n",
    "          )\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots()\n",
    "        colors = sns.color_palette(g.CMAPS['income_classes'], g.INC_NBINS)\n",
    "        for (bin_, df), col in zip(res.groupby(['home_inc_q']), colors):\n",
    "            (df['home_visitors']/1e6).plot(ax=ax, color=col, label=f'Q{bin_}')\n",
    "        plt.xlabel('')\n",
    "        plt.ylabel('Visitors (M)')\n",
    "        plt.legend()\n",
    "        plt.title('Weekly home visitors by income\\n' +\n",
    "                  'quintile of home zip in ' + city.name);\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%time _ = get_poi_vis_by_home_inc(nyc, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Inference</b>: Fewer rich people travel compared to poorer people, both before & after lockdown."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%time _ = get_poi_vis_by_home_inc(chi, plot=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%time _ = get_poi_vis_by_home_inc(il, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Inference</b>: Fewer rich people travel compared to poorer people, both before & after lockdown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dwell-time visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dwell time by POI zip income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dwell time by home zip income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_dwell_by_home_inc(city, imp_zips=True, nbins=5,\n",
    "                          imp_naics=False, plot=False):\n",
    "    \"\"\"\n",
    "    Get the weekly trend of average dwell time over income class of home\n",
    "    visitors.\n",
    "    @param imp_naics: whether filter the OD data for only the important naics\n",
    "    \"\"\"\n",
    "    # get the expanded patterns OD matrix\n",
    "    odX = get_odX(city, imp_zips)\n",
    "    # filter the NAICS, if required\n",
    "    odX = odX[odX['naics'].isin(g.IMP_NAICS.index)] if imp_naics else odX\n",
    "        \n",
    "    # first get the no. of home visitors by POI & home zip income class\n",
    "    res = (odX.rename(columns={f'tot_dwell{nbins}': 'tot_dwell'})\n",
    "           .merge(city.acs_zip['hh_inc_q'].rename('home_inc_q'),\n",
    "                  left_on='home_zip', right_index=True)\n",
    "           .groupby(['week', 'poi_id', 'home_inc_q'])\n",
    "           .agg({'tot_dwell': 'first', 'home_visitors': sum})\n",
    "           .reset_index('home_inc_q')\n",
    "          )\n",
    "    # calculate the total home visitors of each POI\n",
    "    tot_vis_by_poi = (res.groupby(['week', 'poi_id'])\n",
    "                      ['home_visitors'].sum()\n",
    "                      .rename('tot_home_visitors')\n",
    "                     )\n",
    "    # now distribute the POI total dwell time into its income class components\n",
    "    # in proportion of the home visitors in its income classes\n",
    "    res = (res\n",
    "           .merge(tot_vis_by_poi, on=('week', 'poi_id'))\n",
    "           .astype({'tot_dwell': float, 'home_visitors': int,\n",
    "                    'tot_home_visitors': float})\n",
    "           .assign(tot_dwell_inc = lambda x:\n",
    "                   x['tot_dwell']*x['home_visitors']/x['tot_home_visitors'])\n",
    "           .drop(columns=['tot_dwell'])\n",
    "           .rename(columns={'tot_dwell_inc': 'tot_dwell'})\n",
    "           .groupby(['week', 'home_inc_q'])\n",
    "           .sum()\n",
    "           .assign(avg_dwell = lambda x: x['tot_dwell']/x['home_visitors'])\n",
    "           .drop(columns=['tot_dwell', 'tot_home_visitors'])\n",
    "           .reset_index()\n",
    "           .assign(week = lambda x: g.int2date(x['week']))\n",
    "           .set_index('week')\n",
    "          )\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots()\n",
    "        colors = sns.color_palette(g.CMAPS['income_classes'], g.INC_NBINS)\n",
    "        for (bin_, df), col in zip(res.groupby(['home_inc_q']), colors):\n",
    "            (df['avg_dwell']).plot(ax=ax, color=col, label=f'Q{bin_}')\n",
    "        plt.xlabel('')\n",
    "        plt.ylabel('Dwell time (min)')\n",
    "        plt.legend()\n",
    "        plt.title(f'Weekly avg. dwell time ({nbins} bins) by income\\n' +\n",
    "                  'quintile of home zip in ' + city.name);\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%time _ = get_dwell_by_home_inc(nyc, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%time _ = get_dwell_by_home_inc(nyc, imp_naics=True, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%time _ = get_dwell_by_home_inc(nyc, nbins=4, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%time _ = get_dwell_by_home_inc(nyc, nbins=4, imp_naics=True, plot=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%time _ = get_dwell_by_home_inc(chi, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dwell time by industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_vis_by_dwell_naics(city, imp_zips=True):\n",
    "    \"\"\"\n",
    "    Calc. the total weekly POI visits by industry in different dwell time\n",
    "    buckets.\n",
    "    \"\"\"\n",
    "    res = (get_pat(city, imp_zips)\n",
    "           [['week', 'naics'] + g.DWELL_BINS['names']]\n",
    "           .merge(g.IMP_NAICS['category'], on='naics')\n",
    "           .drop(columns='naics')\n",
    "           .groupby(['category', 'week'])\n",
    "           .sum()\n",
    "           .reset_index()\n",
    "           .assign(week = lambda x: g.int2date(x['week']))\n",
    "           .set_index(['category', 'week'])\n",
    "          )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "peek(get_vis_by_dwell_naics(nyc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_visits_by_naics_dwell_bin(city, imp_zips=True,\n",
    "                                   pre_date=None, post_date=None):\n",
    "    \"\"\"\n",
    "    Plot the trend of total weekly visits by dwell-time bucket and industry.\n",
    "    @param pre_date, post_date: <str> dates to be considered representative\n",
    "    of the pre-restriction and post-restriction era (must be a Monday)\n",
    "    \"\"\"\n",
    "    data = get_vis_by_dwell_naics(city, imp_zips)\n",
    "    fig, ax = plt.subplots(3, 4, figsize=(16, 9), dpi=60, sharex=True)\n",
    "    ax = ax.flatten()\n",
    "    for i, (cat, df) in enumerate(data.groupby('category')):\n",
    "        ((df.reset_index('category', drop=True)/1e3)\n",
    "         .plot(ax=ax[i], color=sns.color_palette(g.CMAPS['dwell_bins'], 5)))\n",
    "        if i != 0:\n",
    "            ax[i].legend().remove()\n",
    "        ax[i].set_title('{} ({:.0f}k)'.format(cat, df.sum().mean()/1e3))\n",
    "        \n",
    "        # plot dates\n",
    "        if pre_date is not None:\n",
    "            ax[i].axvline(g.str2date(pre_date), color='grey')\n",
    "        if post_date is not None:\n",
    "            ax[i].axvline(g.str2date(post_date), color='grey')\n",
    "    fig.suptitle('Weekly visits (k) by dwell time buckets across industry in ' +\n",
    "                 city.name + '\\n (all-time weekly average shown in parentheses)',\n",
    "                 fontsize=20, y=0.98)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%time plot_visits_by_naics_dwell_bin(nyc, '2020-01-27', '2020-04-27')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%time plot_visits_by_naics_dwell_bin(chi, '2020-01-27', '2020-04-27')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dwell time distribution on a date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_dwell_distr_by_naics_on(city, date, imp_zips=True, plot=False):\n",
    "    \"\"\"\n",
    "    Filter the discrete probability distribution of dwell time a city on a\n",
    "    particular date by industry, used to compare the change in composition.\n",
    "    \"\"\"\n",
    "    res = (get_vis_by_dwell_naics(city, imp_zips)\n",
    "          .reset_index('category')\n",
    "          .loc[g.str2date(date)]\n",
    "          .set_index('category'))\n",
    "    res = res.divide(res.sum(1), axis=0)\n",
    "    \n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        res.plot.barh(ax=ax, stacked=True, cmap=g.CMAPS['dwell_bins'])\n",
    "        plt.legend(bbox_to_anchor=(1.01, 1))\n",
    "        plt.ylabel('')\n",
    "        plt.title('Dwell time composition by industry:\\n{}, {}'\n",
    "                  .format(city.name, g.str2date(date).strftime('%d %b')))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_ = get_dwell_distr_by_naics_on(nyc, '2020-01-27', plot=True)\n",
    "peek(_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "_ = get_dwell_distr_by_naics_on(nyc, '2020-04-27', plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change in dwell time distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_change_dwell_distr(city, b4_date, aft_date, plot=False):\n",
    "    \"\"\"\n",
    "    Get the difference in the dwell time discrete probability distribution of a\n",
    "    city between two dates by industry to see how dwell time buckets had\n",
    "    different relative change in proportion of visits by industry.\n",
    "    \"\"\"\n",
    "    # get the distributions on before and after dates\n",
    "    b4_distr = get_dwell_distr_by_naics_on(city, b4_date)\n",
    "    aft_distr = get_dwell_distr_by_naics_on(city, aft_date)\n",
    "    # get the element wise difference to get change in percentage points\n",
    "    res = (aft_distr - b4_distr) * 100\n",
    "    \n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        res.plot.barh(ax=ax, stacked=True, cmap=g.CMAPS['dwell_bins'])\n",
    "        plt.legend(bbox_to_anchor=(1.01, 1))\n",
    "        plt.ylabel('')\n",
    "        plt.xlabel('Change in percentage points')\n",
    "        plt.title('Change in dwell time composition in {} \\n between {} and {}'\n",
    "              .format(city.name, g.str2date(b4_date).strftime('%d %b'),\n",
    "                      g.str2date(aft_date).strftime('%d %b')))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_ = get_change_dwell_distr(nyc, '2020-01-27', '2020-04-27', plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_ = get_change_dwell_distr(nyc, '2020-03-09', '2020-03-23', plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_ = get_change_dwell_distr(nyc, '2020-03-16', '2020-03-23', plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate dwell time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "city = nyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(nyc.pois.loc[nyc.in_hosp_pois]\n",
    " .query('naics == 722513')\n",
    " .merge(POIS.drop(columns=['zip']), on='poi_id')\n",
    " .merge(nyc.acs_zip['hh_inc_q'], on='zip')\n",
    " .rename(columns={'hh_inc_q': 'poi_income_q'})\n",
    " [['location_name', 'street_address', 'city', 'poi_income_q']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(get_pat(nyc, True, True)\n",
    " .query('naics == 722513 & week == 200330')\n",
    " .merge(nyc.acs_zip['hh_inc_q'], on='zip')\n",
    " [['poi_id', 'hh_inc_q', 'visits5', 'tot_dwell5']]\n",
    " .set_index('poi_id').sort_index()\n",
    ").join(\n",
    "    (get_odX(nyc, True, True)\n",
    "    .query('naics == 722513 & week == 200330')\n",
    "    .merge(nyc.acs_zip['hh_inc_q'], left_on='poi_zip', right_index=True)\n",
    "    [['poi_id', 'hh_inc_q', 'visits5', 'tot_dwell5']]\n",
    "    .groupby('poi_id').first().sort_index()\n",
    "    ),\n",
    "    lsuffix='_pat', rsuffix='_odX'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "(get_odX(nyc, True, True)\n",
    " .query('naics == 722513 & week == 200330')\n",
    " .merge(nyc.acs_zip['hh_inc_q'], left_on='poi_zip', right_index=True)\n",
    " [['poi_id', 'hh_inc_q', 'visits5', 'tot_dwell5']]\n",
    " .groupby('poi_id').first().sort_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "pd.concat([\n",
    "    (get_pat(city, imp_zips=True, out_hosp=False)\n",
    "     .pipe(lambda x: x[x.week == 200330])\n",
    "     .merge(city.acs_zip['hh_inc_q'].rename('poi_inc_q'), on='zip')\n",
    "     .merge(g.IMP_NAICS['category'], on='naics')\n",
    "     .query('category == \"Fast food/Takeout\"')\n",
    "     .groupby(['poi_inc_q', 'category'])\n",
    "     .agg({'med_dwell': np.mean, 'visits5': sum, 'visits4': sum,'tot_dwell4': sum, 'tot_dwell5': sum})\n",
    "     .assign(avg_dwell4 = lambda x: x['tot_dwell4']/x['visits4'],\n",
    "             avg_dwell5 = lambda x: x['tot_dwell5']/x['visits5'])\n",
    "     ['avg_dwell5'].reset_index()\n",
    "     .drop(columns=['category'])\n",
    "     .set_index('poi_inc_q')\n",
    "     .rename(columns={'avg_dwell5': 'without_removing'})\n",
    "    ),\n",
    "    (get_pat(city, imp_zips=True, out_hosp=True)\n",
    "     .pipe(lambda x: x[x.week == 200330])\n",
    "     .merge(city.acs_zip['hh_inc_q'].rename('poi_inc_q'), on='zip')\n",
    "     .merge(g.IMP_NAICS['category'], on='naics')\n",
    "     .query('category == \"Fast food/Takeout\"')\n",
    "     .groupby(['poi_inc_q', 'category'])\n",
    "     .agg({'med_dwell': np.mean, 'visits5': sum, 'visits4': sum,'tot_dwell4': sum, 'tot_dwell5': sum})\n",
    "     .assign(avg_dwell4 = lambda x: x['tot_dwell4']/x['visits4'],\n",
    "             avg_dwell5 = lambda x: x['tot_dwell5']/x['visits5'])\n",
    "     ['avg_dwell5'].reset_index()\n",
    "     .drop(columns=['category'])\n",
    "     .set_index('poi_inc_q')\n",
    "     .rename(columns={'avg_dwell5': 'after_removing'})\n",
    "    )\n",
    "], axis=1).plot.bar(cmap='tab10', figsize=(5, 3))\n",
    "plt.legend(loc='lower center')\n",
    "plt.ylabel('Avg. dwell time (min)')\n",
    "plt.xlabel('Income quintile of POI ZCTAs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "pd.concat([\n",
    "(get_odX(city, True, out_hosp=False)\n",
    "          .query('week == 200330')\n",
    "          .merge(g.IMP_NAICS['category'], on='naics')\n",
    " .query('category == \"Fast food/Takeout\"')\n",
    "          .merge(city.acs_zip['hh_inc_q'].rename('poi_inc_q'),\n",
    "                 left_on='poi_zip', right_index=True)\n",
    "          .merge(city.acs_zip['hh_inc_q'].rename('home_inc_q'),\n",
    "                 left_on='home_zip', right_index=True)\n",
    "          .groupby(['category', 'home_inc_q'])\n",
    "          .agg({**{'med_dwell': np.mean}, **{x: sum for x in [\n",
    "              'poi_visitors', 'visits4', 'visits5', 'tot_dwell4', 'tot_dwell5']}})\n",
    "          .assign(avg_dwell4 = lambda x: x['tot_dwell4']/x['visits4'],\n",
    "                  avg_dwell5 = lambda x: x['tot_dwell5']/x['visits5'])\n",
    "          .drop(columns=['tot_dwell4', 'tot_dwell5'])\n",
    "          ['avg_dwell5'].reset_index()\n",
    " .drop(columns='category')\n",
    " .set_index('home_inc_q')\n",
    " .rename(columns={'avg_dwell5': 'before_removing'})\n",
    "),\n",
    "(get_odX(city, True, out_hosp=True)\n",
    "          .query('week == 200330')\n",
    "          .merge(g.IMP_NAICS['category'], on='naics')\n",
    " .query('category == \"Fast food/Takeout\"')\n",
    "          .merge(city.acs_zip['hh_inc_q'].rename('poi_inc_q'),\n",
    "                 left_on='poi_zip', right_index=True)\n",
    "          .merge(city.acs_zip['hh_inc_q'].rename('home_inc_q'),\n",
    "                 left_on='home_zip', right_index=True)\n",
    "          .groupby(['category', 'home_inc_q'])\n",
    "          .agg({**{'med_dwell': np.mean}, **{x: sum for x in [\n",
    "              'poi_visitors', 'visits4', 'visits5', 'tot_dwell4', 'tot_dwell5']}})\n",
    "          .assign(avg_dwell4 = lambda x: x['tot_dwell4']/x['visits4'],\n",
    "                  avg_dwell5 = lambda x: x['tot_dwell5']/x['visits5'])\n",
    "          .drop(columns=['tot_dwell4', 'tot_dwell5'])\n",
    "          ['avg_dwell5'].reset_index()\n",
    " .drop(columns='category')\n",
    " .set_index('home_inc_q')\n",
    " .rename(columns={'avg_dwell5': 'after_removing'})\n",
    ")\n",
    "], axis=1).plot.bar(cmap='tab10', figsize=(5, 3))\n",
    "plt.legend(loc='lower center')\n",
    "plt.ylabel('Avg. dwell time (min)')\n",
    "plt.xlabel('Income quintile of visitor ZCTAs');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By POI income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def dwell_by_naics_inc_on_date(city, date, measure='avg_dwell5',\n",
    "                               imp_zips=True, out_hosp=True, plot=True):\n",
    "    \"\"\"\n",
    "    Get the average dwell time on a specific date of different industries by\n",
    "    income class of the POI zip.\n",
    "    @param measure: <str> use one of these 3 measures to average dwell time:\n",
    "        1. avg. of weekly median,\n",
    "        2. avg. of 1st 4 bins,\n",
    "        3. avg. of all bins with last bin = 240 min\n",
    "    \"\"\"\n",
    "    # add the column for visits of dwell bin 5\n",
    "    df = get_pat(city, imp_zips, out_hosp)\n",
    "    # filter the data of the given date\n",
    "    df = df[df['week'] == int(date.replace('-', '')[2:])]\n",
    "    # get the POI income bin\n",
    "    df = df.merge(city.acs_zip['hh_inc_q'].rename('poi_inc_q'), on='zip')\n",
    "    # aggregate the dwell time measures\n",
    "    df = (df.merge(g.IMP_NAICS['category'], on='naics')\n",
    "          .groupby(['poi_inc_q', 'category'])\n",
    "          .agg({'med_dwell': np.mean, 'visits5': sum, 'visits4': sum,\n",
    "                'tot_dwell4': sum, 'tot_dwell5': sum})\n",
    "          .assign(avg_dwell4 = lambda x: x['tot_dwell4']/x['visits4'],\n",
    "                  avg_dwell5 = lambda x: x['tot_dwell5']/x['visits5'])\n",
    "          [measure].reset_index()\n",
    "         )\n",
    "    # plot the distribution\n",
    "    if plot:\n",
    "        p = sns.catplot(kind='bar', data=df, x='category', y=measure,\n",
    "                        hue='poi_inc_q', palette='summer_r', aspect=1.8,\n",
    "                        height=4)\n",
    "        ax = p.axes[0, 0]\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel('Avg. dwell time (min)')\n",
    "        ax.set_title(f'Avg. dwell time composition on {date} in {city.name}' +\n",
    "                     '\\nby income class of POIs across different industries')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_ = dwell_by_naics_inc_on_date(nyc, '2020-03-30', 'avg_dwell5', True, out_hosp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_.query('category == \"Fast food/Takeout\"').drop(columns=['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_ = dwell_by_naics_inc_on_date(nyc, '2020-03-30', 'avg_dwell5', True, out_hosp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_.query('category == \"Fast food/Takeout\"').drop(columns=['category'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "_ = dwell_by_naics_inc_on_date(nyc, '2020-03-30', 'med_dwell', True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "_ = dwell_by_naics_inc_on_date(chi, '2020-03-30', 'avg_dwell4', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Of specific industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def dwell_by_inc_of_naics(city, week, industry, imp_zips=True, out_hosp=True):\n",
    "    target_naics = g.IMP_NAICS.query(f'category == \"{industry}\"').index[0]\n",
    "    # filter the data\n",
    "    df = (get_odX(city, imp_zips, out_hosp)\n",
    "          .query(f'naics == {target_naics}')\n",
    "          .query('week == ' + week.replace('-', '')[2:])\n",
    "          .drop(columns=['week', 'naics'])\n",
    "          .merge(city.acs_zip['hh_inc_q'].rename('poi_inc_q'),\n",
    "                 left_on='poi_zip', right_index=True)\n",
    "          .groupby('poi_inc_q')\n",
    "#           .groupby('home_inc_bin')\n",
    "          .agg({**{'med_dwell': np.mean}, **{x: sum for x in [\n",
    "              'poi_visitors', 'visits5', 'visits4', 'tot_dwell4',\n",
    "              'tot_dwell5']}})\n",
    "          .assign(avg_dwell4 = lambda x: x['tot_dwell4']/x['visits4'],\n",
    "                  avg_dwell5 = lambda x: x['tot_dwell5']/x['visits5'])\n",
    "          .drop(columns=['tot_dwell4', 'tot_dwell5'])\n",
    "         )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%time dwell_by_inc_of_naics(nyc, '2020-03-30', 'Fast food/Takeout', out_hosp=False)[['poi_visitors', 'avg_dwell5']].avg_dwell5.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%time dwell_by_inc_of_naics(nyc, '2020-03-30', 'Fast food/Takeout', out_hosp=True)[['poi_visitors', 'avg_dwell5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def od_dwell_by_naics_inc_on_date(city, week, dwell_var='avg_dwell5',\n",
    "                                  inc_q_var='home_inc_q', imp_zips=True,\n",
    "                                  out_hosp=True, plot=True):\n",
    "    \"\"\"\n",
    "    Get the average dwell time on a specific date of different industries by\n",
    "    income class of the POI zip but use the `city.od` table instead of `city.pat`.\n",
    "    @param measure: <str> use one of these 3 measures to average dwell time:\n",
    "        1. avg. of weekly median,\n",
    "        2. avg. of 1st 4 bins,\n",
    "        3. avg. of all bins with last bin = 240 min\n",
    "    \"\"\"\n",
    "#     imp_pois = (city.pois.merge(g.IMP_NAICS, on='naics')\n",
    "#                 [['poi_id', 'zip', 'category']])\n",
    "    df = (get_odX(city, imp_zips, out_hosp)\n",
    "          .query('week == ' + week.replace('-', '')[2:])\n",
    "          .merge(g.IMP_NAICS['category'], on='naics')\n",
    "          .merge(city.acs_zip['hh_inc_q'].rename('poi_inc_q'),\n",
    "                 left_on='poi_zip', right_index=True)\n",
    "          .merge(city.acs_zip['hh_inc_q'].rename('home_inc_q'),\n",
    "                 left_on='home_zip', right_index=True)\n",
    "          .groupby(['category', 'home_inc_q'])\n",
    "#           .groupby(['category', 'poi_inc_q'])\n",
    "          .agg({**{'med_dwell': np.mean}, **{x: sum for x in [\n",
    "              'poi_visitors', 'visits4', 'visits5', 'tot_dwell4', 'tot_dwell5']}})\n",
    "          .assign(avg_dwell4 = lambda x: x['tot_dwell4']/x['visits4'],\n",
    "                  avg_dwell5 = lambda x: x['tot_dwell5']/x['visits5'])\n",
    "          .drop(columns=['tot_dwell4', 'tot_dwell5'])\n",
    "          [dwell_var].reset_index()\n",
    "         )\n",
    "    # plot the distribution\n",
    "    if plot:\n",
    "        p = sns.catplot(kind='bar', data=df, x='category', y=dwell_var,\n",
    "                        hue=inc_q_var, palette=g.CMAPS['income_classes'],\n",
    "                        aspect=1.8, height=4)\n",
    "        ax = p.axes[0, 0]\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel('Avg. dwell time (min)')\n",
    "        if inc_q_var == 'poi_inc_q': label = 'POIs'\n",
    "        elif inc_q_var == 'home_inc_q': label = 'home zips'\n",
    "        else: label = ''\n",
    "        ax.set_title(f'Avg. dwell time composition on {week} in {city.name}' +\n",
    "                     f'\\nby income class of {label} across different industries')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_1 = od_dwell_by_naics_inc_on_date(nyc, '2020-03-30', 'avg_dwell5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_2 = od_dwell_by_naics_inc_on_date(nyc, '2020-03-30', 'avg_dwell5', out_hosp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.concat([_2.query('category == \"Fast food/Takeout\"')\n",
    "           .set_index('home_inc_q')['avg_dwell5'].rename('before'),\n",
    "           _1.query('category == \"Fast food/Takeout\"')\n",
    "           .set_index('home_inc_q')['avg_dwell5'].rename('after')\n",
    "           ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exposure (<4 hr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate expsoure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By POI zip income\n",
    "Using patterns, not pat_od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_exp_by_poi_inc(city, exp_var='cei', nbins=5,\n",
    "                        imp_zips=True, plot=True):\n",
    "    \"\"\"\n",
    "    Get the weekly trend of average exposure over income class of home\n",
    "    visitors.\n",
    "    @param var: <str> exposure variable to be used\n",
    "    (column name must be in `city.od`)\n",
    "    \"\"\"\n",
    "    res = (get_pat(city, imp_zips)\n",
    "           .merge(city.acs_zip['hh_inc_q'].rename('poi_inc_q'), on='zip')\n",
    "           .groupby(['poi_inc_q', 'week'])\n",
    "           [['tot_cei', 'exp_visits']].sum()\n",
    "           .assign(cei = lambda x: x['tot_cei']/x['exp_visits'])\n",
    "           .reset_index()\n",
    "           .assign(week = lambda x: g.int2date(x['week']))\n",
    "           .set_index('week')\n",
    "          )\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots()\n",
    "        colors = sns.color_palette(g.CMAPS['income_classes'], g.INC_NBINS)\n",
    "        for (bin_, df), col in zip(res.groupby(['poi_inc_q']), colors):\n",
    "            (df[exp_var]).plot(ax=ax, color=col, label=f'Q{bin_}')\n",
    "        plt.xlabel('')\n",
    "        plt.ylabel('$CEI$ (min-persons/ft)')\n",
    "        plt.legend()\n",
    "        plt.title(f'Weekly avg. $CEI$ ({nbins} bins) by income\\n' +\n",
    "                  'quintile of home zip in ' + city.name);\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_ = get_exp_by_poi_inc(nyc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "_ = get_exp_by_poi_inc(chi)\n",
    "plt.ylim(top=3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By home zip income "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_exp_by_home_inc(city, exp_var='cei', nbins=5,\n",
    "                        imp_zips=True, plot=False):\n",
    "    \"\"\"\n",
    "    Get the weekly trend of average exposure over income class of home\n",
    "    visitors.\n",
    "    @param var: <str> exposure variable to be used\n",
    "    (column name must be in `city.od`)\n",
    "    \"\"\"\n",
    "    res = (get_odX(city, imp_zips)\n",
    "           .merge(city.acs_zip['hh_inc_q'].rename('home_inc_q'),\n",
    "                  left_on='home_zip', right_index=True)\n",
    "           .groupby(['week', 'poi_id', 'home_inc_q'])\n",
    "           .agg({exp_var: 'first', 'home_visitors': sum})\n",
    "           .assign(tot_exp = lambda x: x[exp_var]*x['home_visitors'])\n",
    "           .reset_index()\n",
    "          )\n",
    "    # calculate the total home visitors of each POI\n",
    "    tot_vis_by_poi = (res.groupby(['week', 'poi_id'])\n",
    "                      ['home_visitors'].sum().rename('tot_home_visitors'))\n",
    "    # now distribute the POI total exposure into its income class components\n",
    "    # in proportion of the home visitors in its income classes\n",
    "    res = (res\n",
    "           .merge(tot_vis_by_poi, on=('week', 'poi_id'))\n",
    "           .astype({'tot_exp': float, 'home_visitors': int,\n",
    "                    'tot_home_visitors': float})\n",
    "           .assign(tot_exp_inc = lambda x:\n",
    "                   x['tot_exp']*x['home_visitors']/x['tot_home_visitors'])\n",
    "           .drop(columns=['tot_exp'])\n",
    "           .rename(columns={'tot_exp_inc': 'tot_'+exp_var})\n",
    "           .groupby(['week', 'home_inc_q'])\n",
    "           .sum()\n",
    "           .assign(avg_exp = lambda x: x['tot_'+exp_var]/x['home_visitors'])\n",
    "           .rename(columns={'avg_exp': 'avg_'+exp_var})\n",
    "           .drop(columns=['tot_'+exp_var, 'tot_home_visitors'])\n",
    "           .reset_index()\n",
    "           .assign(week = lambda x: g.int2date(x['week']))\n",
    "           .set_index('week')\n",
    "          )\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots()\n",
    "        colors = sns.color_palette(g.CMAPS['income_classes'], g.INC_NBINS)\n",
    "        for (bin_, df), col in zip(res.groupby(['home_inc_q']), colors):\n",
    "            (df['avg_'+exp_var]).plot(ax=ax, color=col, label=f'Q{bin_}')\n",
    "        plt.xlabel('')\n",
    "        plt.ylabel('$CEI$ (min-persons/ft)')\n",
    "        plt.legend()\n",
    "        plt.title(f'Weekly avg. $CEI$ ({nbins} bins) by income\\n' +\n",
    "                  'quintile of home zip in ' + city.name);\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%time _ = get_exp_by_home_inc(nyc, plot=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%time _ = get_exp_by_home_inc(chi, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By home zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_exp_by_home_zip(city, imp_zips=True, nbins=4):\n",
    "    \"\"\"\n",
    "    Get the weekly trend of average exposure of each zip code of home\n",
    "    visitors.\n",
    "    \"\"\"\n",
    "    odX = (get_odX(city, imp_zips)\n",
    "           .assign(tot_exp = lambda x: x['cei']*x['home_visitors'])\n",
    "           [['poi_id', 'week', 'home_zip', 'home_visitors', 'tot_exp']]\n",
    "          )\n",
    "    # calculate the total home visitors of each POI\n",
    "    tot_vis_by_poi = (odX.groupby(['week', 'poi_id'])\n",
    "                      ['home_visitors'].sum().rename('tot_home_visitors'))\n",
    "    # now distribute the POI total exposure into its income class components\n",
    "    # in proportion of the home visitors in its income classes\n",
    "    res = (odX\n",
    "           .merge(tot_vis_by_poi, on=('week', 'poi_id'))\n",
    "           .astype({'tot_exp': float, 'home_visitors': int,\n",
    "                    'tot_home_visitors': float})\n",
    "           .assign(zip_exp = lambda x:\n",
    "                   x['tot_exp']*x['home_visitors']/x['tot_home_visitors'])\n",
    "           .groupby(['week', 'home_zip'])\n",
    "           [['tot_exp', 'home_visitors']]\n",
    "           .sum()\n",
    "           .assign(avg_exp = lambda x: x['tot_exp']/x['home_visitors'])\n",
    "           .reset_index()\n",
    "           .assign(week = lambda x: g.int2date(x['week']))\n",
    "          )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "nyc.cei_zip_wk = get_exp_by_home_zip(nyc, True)\n",
    "peek(nyc.cei_zip_wk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%time chi.cei_zip_wk = get_exp_by_home_zip(chi, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cases vs exposure (snapshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_cases_vs_mob_by_zip(city, week, xvar='tot_cei', yvar='new_cases',\n",
    "                             plot=True, plot_kde=True, regress=True, dpi=70,\n",
    "                             xmin=0, xmax=None, ymin=0, ymax=None):\n",
    "    \"\"\"\n",
    "    Scatterplot of cases vs mobility measure on a given weekdate where each\n",
    "    point represents a zip code which is colored by its income level.\n",
    "    \"\"\"\n",
    "    # agg the new cases by zip & week\n",
    "    cases = city.cases.groupby(['zip', 'week'])['new_cases'].sum().reset_index()\n",
    "    # fetch the CEI by zip & week\n",
    "    cei_zip = (city.cei_zip_wk\n",
    "               .rename(columns={'avg_exp': 'avg_cei', 'home_zip': 'zip'}))\n",
    "    # calc. total CEI\n",
    "    res = (cei_zip.assign(tot_cei = lambda x: x['avg_cei'] * x['home_visitors']))\n",
    "    # join with the cases data\n",
    "    res = res.merge(cases, on=('week', 'zip'))\n",
    "    # filter the data on the given date\n",
    "    res = res[res['week'] == g.str2date(week)].drop(columns='week')\n",
    "    # get the income bin of the home zip\n",
    "    res = res.merge((city.acs_zip[['tot_pop', 'hh_inc_q']]\n",
    "                     .rename(columns={'hh_inc_q': 'home_inc_q'})), on='zip')\n",
    "    # get the values per unit population\n",
    "    res['tot_cei_per_pop'] = res['tot_cei']/(res['tot_pop']/1000)\n",
    "    res['cases_per_pop'] = res['new_cases']/(res['tot_pop']/1000)\n",
    "    \n",
    "    if plot:\n",
    "        fig = plt.figure(figsize=(8, 3.5), dpi=dpi)\n",
    "        gs = mpl.gridspec.GridSpec(1, 2, width_ratios=[2.5, 1])\n",
    "        ax1, ax2 = plt.subplot(gs[0]), plt.subplot(gs[1])\n",
    "        twin = ax1.twinx()\n",
    "        colors = g.COLORS['income_classes5']\n",
    "        markers = ['o', '^', '*', 'P', 'd']        \n",
    "        \n",
    "        # 1st axes: cases vs total exposure scatterplot\n",
    "        for i, (bin_, df) in enumerate(res.groupby('home_inc_q')):\n",
    "            X, Y = df[xvar], df[yvar]\n",
    "            if xvar == 'home_visitors':\n",
    "                X = X/1000\n",
    "            if regress:\n",
    "                model = LinearRegression(fit_intercept=False)\n",
    "                model.fit(X.values.reshape((-1,1)), Y.values)\n",
    "                m = model.coef_[0]\n",
    "                ax1.plot(X.values, m*X.values, color=colors[i], lw=0.5)\n",
    "            if plot_kde:\n",
    "                X.plot.kde(ax=twin, color=colors[i], lw=1, ls='--')\n",
    "            pts = ax1.scatter(X, Y, color=colors[i], label=f'Q{bin_}', s=30,\n",
    "                              marker=markers[i])\n",
    "        ax1.set_xlim(xmin, xmax)\n",
    "        ax1.set_ylim(ymin, ymax)\n",
    "        xlabels = {'tot_cei': 'Total CEI (min/ft)',\n",
    "                   'tot_cei_per_pop': 'Total CEI (min/ft) per 1000 residents',\n",
    "                   'home_visitors': 'Total visitors (k)',\n",
    "                   'avg_cei': 'Avg. CEI (min/ft)'}\n",
    "        ylabels ={'new_cases': 'New weekly cases',\n",
    "                  'cases_per_pop': 'Weekly case rate\\n(per 1000 residents)'}\n",
    "        ytitle = 'Case rate' if yvar == 'cases_per_pop' else 'Cases'\n",
    "        titles = {'tot_cei': f'{ytitle} vs total exposure',\n",
    "                  'tot_cei_per_pop': f'{ytitle} vs total exposure per unit population',\n",
    "                  'home_visitors': f'{ytitle} vs total no. of visitors',\n",
    "                  'avg_cei': f'{ytitle} vs avg. CEI'}\n",
    "        ax1.set_xlabel(xlabels[xvar])\n",
    "        ax1.set_ylabel(ylabels[yvar])\n",
    "        wk = g.str2date(week)\n",
    "        ax1.set_title('{}\\n in {} during {} - {}'.format(\n",
    "            titles[xvar], city.name, wk.strftime(\"%d %b\"),\n",
    "            (wk + pd.DateOffset(days=6)).strftime(\"%d %b\")))\n",
    "        ax1.legend(fontsize=10)\n",
    "        \n",
    "        # 2nd axes: total visitors by income class\n",
    "        visitors = res.groupby('home_inc_q')['home_visitors'].sum()/1e3\n",
    "        visitors.plot.barh(ax=ax2, x='home_inc_q', y='home_visitors', color=colors)\n",
    "        ax2.set_xlabel('Total home visitors (k)')\n",
    "        ax2.set_ylabel('Income class')\n",
    "        ax2.set_title('Visitor income\\ndistribution')\n",
    "        for i, v in enumerate(visitors):\n",
    "            ax2.text(20, i-0.1, f'{v/visitors.sum()*100:.2f}%')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total CEI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_cases_vs_mob_by_zip(nyc, '2020-04-06', 'tot_cei', xmax=13000, dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_cases_vs_mob_by_zip(nyc, '2020-03-30', 'tot_cei', xmax=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_cases_vs_mob_by_zip(nyc, '2020-05-04', 'tot_cei', xmax=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_cases_vs_mob_by_zip(nyc, '2020-06-22', 'tot_cei', xmax=25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total CEI per unit population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_cases_vs_mob_by_zip(nyc, '2020-03-30', 'tot_cei_per_pop', xmax=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_cases_vs_mob_by_zip(nyc, '2020-04-06', 'tot_cei_per_pop', xmax=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total CEI & cases per unit population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_cases_vs_mob_by_zip(nyc, '2020-03-30', 'tot_cei_per_pop', 'cases_per_pop', xmax=200, ymax=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_cases_vs_mob_by_zip(nyc, '2020-04-06', 'tot_cei_per_pop', 'cases_per_pop',\n",
    "                             regress=False, xmax=200, ymax=15, dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avg CEI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_cases_vs_mob_by_zip(nyc, '2020-03-30', 'avg_cei', xmin=0.25, xmax=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_cases_vs_mob_by_zip(nyc, '2020-04-06', 'avg_cei', xmin=0.25, xmax=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_cases_vs_mob_by_zip(nyc, '2020-06-22', 'avg_cei', xmin=0.25, xmax=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total visitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_cases_vs_mob_by_zip(nyc, '2020-03-30', 'home_visitors', xmax=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_cases_vs_mob_by_zip(nyc, '2020-04-06', 'home_visitors', xmax=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_cases_vs_mob_by_zip(nyc, '2020-06-22', 'home_visitors', xmax=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cases vs exposure\n",
    "Level: Zip-daily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_modelX(city, xvar='tot_cei', lag=7, start_date='2020-03-01', dropna=True):\n",
    "    \"\"\"\n",
    "    Prepare the dataset for training the SEM model as shown in the PNAS paper\n",
    "    https://www.pnas.org/content/117/44/27087\n",
    "    \"\"\"\n",
    "    # get the zip-daily level exposure data\n",
    "    res = (\n",
    "        city.exp_daily\n",
    "        .reset_index(['poi_id', 'date'])\n",
    "        .pipe(lambda x: x[x['date'] >= g.strdate2int(start_date)])\n",
    "        .merge(city.pois['zip'], on='poi_id')\n",
    "        .merge(city.imp_zips)\n",
    "        .assign(tot_cei = lambda x: x['cei']*x['exp_visits'])\n",
    "        .groupby(['zip', 'date'])\n",
    "        [['exp_visits', 'tot_cei']].sum()\n",
    "        .assign(avg_cei = lambda x: x['tot_cei']/x['exp_visits'])\n",
    "        .reset_index()\n",
    "        .assign(date = lambda x: g.int2date(x['date']))\n",
    "    )\n",
    "    # add the social distancing info\n",
    "    sd = (g.map_cbg_zip(city.sd.reset_index())\n",
    "          .assign(tot_time_home = lambda x: x['time_home']*x['tot_dev'])\n",
    "          .drop(columns=['cbg', 'time_home'])\n",
    "          .groupby(['zip', 'date']).sum()\n",
    "          .reset_index()\n",
    "          .merge(city.imp_zips, on='zip')\n",
    "          .assign(prop_home = lambda x: x['dev_home']/(x['tot_dev']+1),\n",
    "                  time_home = lambda x: x['tot_time_home']/(x['tot_dev']+1))\n",
    "          .drop(columns=['tot_time_home', 'dev_home'])\n",
    "          .astype({'tot_dev': np.int32})\n",
    "         )\n",
    "    res = res.merge(sd, on=('zip', 'date'))\n",
    "    \n",
    "    # add census data\n",
    "    res = (res.merge(city.acs_zip[['avg_hh_income'] + g.VUL_VARS], on='zip')\n",
    "           .assign(income = lambda x: x['avg_hh_income']/1e3)\n",
    "           .drop(columns=['avg_hh_income'])\n",
    "          )\n",
    "    # add cases data\n",
    "    res = (res.merge(city.cases\n",
    "                     .rename(columns={'new_cases': 'cases', 'new_tests': 'tests'})\n",
    "                     [['zip', 'date', 'cases', 'tests']],\n",
    "                     on=('zip', 'date'), how='left')\n",
    "           .pipe(lambda x: x[x['date'] <= g.int2date(200628)])\n",
    "           .sort_values('date')\n",
    "           .assign(cases = lambda x: x['cases'].fillna(0),\n",
    "                   tests = lambda x: x['tests'].fillna(0))\n",
    "    )\n",
    "    # get the lag adjusted measures\n",
    "    res = pd.concat([\n",
    "        res, res.groupby('zip')['cases'].shift().rename('cases_prev'),\n",
    "        res.groupby('zip')['tests'].shift().rename('tests_prev'),\n",
    "        res.groupby('zip')[xvar].shift(lag).rename(xvar+'_lag'),\n",
    "        res.groupby('zip')[xvar].shift(lag+1).rename(xvar+'_lag_prev')\n",
    "    ], axis=1)\n",
    "    res = res.set_index(['zip', 'date']).sort_index()\n",
    "    \n",
    "    # make sure all values are non-negative\n",
    "    res = res[res >= 0].reset_index()\n",
    "    # add the log columns\n",
    "    xyvars = ['cases', 'cases_prev', 'tests', 'tests_prev', 'income',\n",
    "              xvar+'_lag', xvar+'_lag_prev']\n",
    "    for var in xyvars:\n",
    "        res['log_'+var] = np.log(1 + res[var])\n",
    "    if dropna:\n",
    "        res = res.dropna()\n",
    "    \n",
    "    return res\n",
    "\n",
    "# get_modelX(nyc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "nyc.modelX = get_modelX(nyc, dropna=False)\n",
    "peek(nyc.modelX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "il.modelX = get_modelX(il, dropna=False)\n",
    "peek(il.modelX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "chi.modelX = il.modelX.merge(chi.zips, on='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(nyc.cases.groupby('date')['new_cases'].sum()\n",
    ".pipe(lambda x: x[(x.index > g.int2date(200402)) & (x.index <= g.int2date(200628))])\n",
    "# .rolling(7).mean()\n",
    " .plot())\n",
    "plt.xlim(g.int2date(200401), g.int2date(200630))\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(nyc.modelX.groupby('date')['cases'].sum()\n",
    " .pipe(lambda x: x[x.index >= g.int2date(200402)])\n",
    "#  .rolling(7).mean()\n",
    " .plot())\n",
    "plt.xlim(g.int2date(200401), g.int2date(200630));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(nyc.cases.groupby('date')['new_cases'].sum()\n",
    ".pipe(lambda x: x[(x.index > g.int2date(200402)) & (x.index <= g.int2date(200628))])\n",
    "# .rolling(7).mean()\n",
    " .plot())\n",
    "plt.xlim(g.int2date(200401), g.int2date(200630))\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(il.modelX.groupby('date')['tests'].sum()\n",
    " .pipe(lambda x: x[x.index >= g.int2date(200402)])\n",
    "#  .rolling(7).mean()\n",
    " .plot())\n",
    "plt.xlim(g.int2date(200401), g.int2date(200630));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(chi.modelX.groupby('date')['tests'].sum()\n",
    " .pipe(lambda x: x[x.index >= g.int2date(200402)])\n",
    "#  .rolling(7).mean()\n",
    " .plot())\n",
    "plt.xlim(g.int2date(200401), g.int2date(200630));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nyc.modelX.dropna().to_csv(nyc.dir + '/zip_modelX.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "il.modelX.dropna().to_csv(il.dir + '/zip_modelX.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "chi.modelX.dropna().to_csv(chi.dir + '/zip_modelX.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "def fig_study_area_grid(date='2020-04-18'):\n",
    "    date = g.str2date(date)\n",
    "    fig = plt.figure(figsize=(10, 11), dpi=70)\n",
    "    gs = mpl.gridspec.GridSpec(2, 2, width_ratios=[1.6, 1])\n",
    "    \n",
    "    def plot_colorbar(ax, data, cmap, frac=0.03):\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(\n",
    "            vmin=data.min(), vmax=data.max())); sm._A = []\n",
    "        cbar = fig.colorbar(sm, ax=ax, fraction=frac, pad=0.04, aspect=30)\n",
    "    \n",
    "    for i, c in enumerate([nyc, chi]):\n",
    "        ax0 = plt.subplot(gs[0, i])\n",
    "        ax1 = plt.subplot(gs[1, i])\n",
    "\n",
    "        # plot cases\n",
    "        cases = gp.GeoDataFrame(\n",
    "            c.cases[c.cases['date'] == date]\n",
    "            [['zip', 'cum_cases']].merge(c.shp_zip))\n",
    "        min_cases, max_cases = cases['cum_cases'].min(), cases['cum_cases'].max()\n",
    "        cases.plot(column='cum_cases', cmap='inferno_r', ax=ax0)\n",
    "        ax0.set_title('{}: Total cases on {}'.format(c.name, date.strftime('%d %b')))\n",
    "        plot_colorbar(ax0, cases['cum_cases'], 'inferno_r', frac=0.03 if c==nyc else 0.048)\n",
    "\n",
    "        # plot exposure\n",
    "        exp = gp.GeoDataFrame(\n",
    "            c.modelX.reset_index()\n",
    "            .pipe(lambda x: x[x['date'] == date])\n",
    "            [['zip', 'tot_cei']].merge(c.shp_zip))\n",
    "        min_exp, max_exp = exp['tot_cei'].min(), exp['tot_cei'].max()\n",
    "        exp.plot(column='tot_cei', cmap='cividis_r', ax=ax1)\n",
    "        ax1.set_title('{}: CEI on {}'.format(c.name, date.strftime('%d %b')))\n",
    "        plot_colorbar(ax1, exp['tot_cei'], 'cividis_r', frac=0.03 if c==nyc else 0.048)\n",
    "        \n",
    "        # plot the centroids\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore')\n",
    "            inc_colors = {i+1: g.COLORS['income_classes5'][i] for i in range(5)}\n",
    "            centroids = (c.shp_zip.merge(c.acs_zip['hh_inc_q'], on='zip')\n",
    "                         .assign(centroid = lambda x: x['geometry']\n",
    "                                 .to_crs(epsg=4269).centroid,\n",
    "                                 color = lambda x: x['hh_inc_q'].map(inc_colors))\n",
    "                         .drop(columns=['geometry'])\n",
    "                         .rename(columns={'centroid': 'geometry'}))\n",
    "        for ax_ in [ax0, ax1]:\n",
    "            centroids.plot(ax=ax_, color=centroids['color'], markersize=5)\n",
    "            ax_.set_xticks([])\n",
    "            ax_.set_yticks([])\n",
    "    plt.tight_layout()\n",
    "    \n",
    "fig_study_area_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def fig_study_area_horz(date='2020-04-20', dpi=70):\n",
    "    date = g.str2date(date)\n",
    "    last_week = [date - pd.DateOffset(days=x) for x in range(7)]\n",
    "    fig = plt.figure(figsize=(15, 5), dpi=dpi)\n",
    "    gs = mpl.gridspec.GridSpec(1, 4, width_ratios=[1.6, 1, 1.6, 1])\n",
    "    \n",
    "    def plot_colorbar(ax, data, cmap, frac=0.03):\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(\n",
    "            vmin=data.min(), vmax=data.max())); sm._A = []\n",
    "        cbar = fig.colorbar(sm, ax=ax, fraction=frac, pad=0.04, aspect=30)\n",
    "    \n",
    "    for i, c in enumerate([nyc, chi]):\n",
    "        ax0 = plt.subplot(gs[0, i])\n",
    "        ax1 = plt.subplot(gs[0, i+2])\n",
    "\n",
    "        # plot cases of the last week\n",
    "        cases = gp.GeoDataFrame(\n",
    "            c.cases.pipe(lambda x: x[x['date'].isin(last_week)])\n",
    "            [['zip', 'cum_cases']].merge(c.shp_zip))\n",
    "        min_cases, max_cases = cases['cum_cases'].min(), cases['cum_cases'].max()\n",
    "        cases.plot(column='cum_cases', cmap='inferno_r', ax=ax0)\n",
    "        ax0.set_title('{}\\nTotal cases'.format(c.name))\n",
    "        plot_colorbar(ax0, cases['cum_cases'], 'inferno_r', frac=0.03 if c==nyc else 0.048)\n",
    "\n",
    "        # plot exposure\n",
    "        exp = gp.GeoDataFrame(\n",
    "#             (c.modelX.reset_index()\n",
    "#             .pipe(lambda x: x[x['date'] <= date])\n",
    "#             .groupby('zip')['tot_cei'].sum()/1e5.reset_index()\n",
    "            c.cei_zip_wk.pipe(lambda x: x[x.week == date])\n",
    "            .rename(columns={'home_zip': 'zip', 'tot_exp': 'tot_cei'})\n",
    "            .merge(c.shp_zip))\n",
    "        min_exp, max_exp = exp['tot_cei'].min(), exp['tot_cei'].max()\n",
    "        exp.plot(column='tot_cei', cmap='plasma_r', ax=ax1)\n",
    "        ax1.set_title('{}\\nTotal CEI (min/ft)'.format(c.name))\n",
    "        plot_colorbar(ax1, exp['tot_cei'], 'plasma_r', frac=0.03 if c==nyc else 0.048)\n",
    "        \n",
    "        # plot the centroids\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore')\n",
    "            inc_colors = {i+1: g.COLORS['income_classes5'][i] for i in range(5)}\n",
    "            centroids = (c.shp_zip.merge(c.acs_zip['hh_inc_q'], on='zip')\n",
    "                         .assign(centroid = lambda x: x['geometry']\n",
    "                                 .to_crs(epsg=4269).centroid,\n",
    "                                 color = lambda x: x['hh_inc_q'].map(inc_colors))\n",
    "                         .drop(columns=['geometry'])\n",
    "                         .rename(columns={'centroid': 'geometry'}))\n",
    "        for ax_ in [ax0, ax1]:\n",
    "            centroids.plot(ax=ax_, color=centroids['color'], markersize=5)\n",
    "            ax_.set_xticks([])\n",
    "            ax_.set_yticks([])\n",
    "    plt.tight_layout()\n",
    "    \n",
    "fig_study_area_horz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fig_overall_trends(win=7, dpi=70):\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(12, 3), dpi=dpi)\n",
    "    ax = ax.flatten()\n",
    "    for c, ls, start in zip([nyc, chi], ['--', (0, (1, 0.8))], [200402, 200418]):\n",
    "        df = (c.modelX[['date', 'cases', 'tot_cei', 'tot_dev', 'prop_home', 'time_home']]\n",
    "              .assign(tot_time_home = lambda x: x['time_home']*x['tot_dev'],\n",
    "                      dev_home = lambda x: x['prop_home']*x['tot_dev'])\n",
    "              .groupby('date').sum()\n",
    "#               .agg({'tot_cei': np.mean, 'tot_time_home': sum, 'dev_home': sum,\n",
    "#                     'tot_dev': sum, 'cases': sum})\n",
    "              .assign(time_home = lambda x: x['tot_time_home']/x['tot_dev'],\n",
    "                      prop_home = lambda x: x['dev_home']/x['tot_dev'])\n",
    "              .drop(columns=['tot_time_home', 'dev_home', 'tot_dev']))\n",
    "        \n",
    "        def plot_trend(data, ax, title, ylab, lgnd=c.name):\n",
    "            data.plot(ax=ax, alpha=0.3, color=c.color, ls=ls, label='_')\n",
    "            data.rolling(win).mean().shift(-win).plot(ax=ax, color=c.color, ls=ls, lw=2, label=lgnd)\n",
    "            ax.set_title(title, fontsize=14)\n",
    "            ax.set_xlabel('')\n",
    "            ax.set_ylabel(ylab, fontsize=13)\n",
    "            ax.legend(fontsize=12)\n",
    "        \n",
    "        plot_trend(df['cases'], ax[0], 'New positive cases', 'No. of cases')\n",
    "        plot_trend(df['tot_cei']/1e5, ax[1], 'Total CEI', 'CEI ($10^5$ min/ft)')\n",
    "        plot_trend(df['prop_home'], ax[2], 'Proportion Stay at Home', 'Fraction of devices')\n",
    "        plot_trend(df['time_home'], ax[3], 'Time Spent at Home', 'Time (h)')\n",
    "        \n",
    "        # first dates of the cases data\n",
    "        ax[0].axvline(g.int2date(start), color=c.color, lw=0.75, ls='-')\n",
    "#         ax[0].text(g.int2date(start + 2), 0, 'Cases available', rotation=90,\n",
    "#                    ha='left', va='bottom', fontsize=8, color='k')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    \n",
    "fig_overall_trends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def fig_exp_by_nacis(plot=True, start='2020-02-01', dpi=70):\n",
    "    if plot:\n",
    "        nrow, ncol = 3, 4\n",
    "        fig, axs = plt.subplots(nrow, ncol, figsize=(13, 7), dpi=dpi,\n",
    "                                sharex=True, sharey=False)\n",
    "    daily_exp = pd.DataFrame()\n",
    "    for c in [nyc, chi]:\n",
    "        res = (c.exp_daily.reset_index()\n",
    "               .assign(tot_cei = lambda x: x['cei']*x['exp_visits'])\n",
    "               .merge(c.pois['naics'], on='poi_id')\n",
    "               .merge(g.IMP_NAICS['category'], on='naics', how='left')\n",
    "               .replace(np.nan, 'Others')\n",
    "               .groupby(['category', 'date'])\n",
    "               [['exp_visits', 'tot_cei']].sum()\n",
    "               .reset_index()\n",
    "               .assign(date = lambda x: g.int2date(x['date']))\n",
    "               .set_index('date'))\n",
    "        daily_exp = daily_exp.append(res.reset_index().assign(city=c.name))\n",
    "        # plot\n",
    "        if plot:\n",
    "            for n, (cat, df) in enumerate(res.query('category != \"Others\"')\n",
    "                                          .groupby('category')):\n",
    "                df = df[df.index >= g.str2date(start)]\n",
    "                # resolve the axes index\n",
    "                i, j = n // ncol, n % ncol\n",
    "                ax = axs[i][j]\n",
    "                # total CEI\n",
    "                ax.plot(df['tot_cei']/1e3, color=c.color, alpha=0.2)\n",
    "                ax.plot(g.roll_avg(df['tot_cei']/1e3), color=c.color, lw=1,\n",
    "                         label=c.name)\n",
    "                # decoration\n",
    "                if i == nrow-1:\n",
    "                    ax.xaxis.set_major_formatter(mpl.dates.DateFormatter('%b'))\n",
    "                if n == 0:\n",
    "                    ax.legend(loc='center right')\n",
    "                # axes title & caption\n",
    "                naics_code = g.IMP_NAICS.query(f'category == \"{cat}\"').index[0]\n",
    "                ax.set_title(f'{cat} ({df.exp_visits.sum()/1e6:.1f}M)', fontsize=14)\n",
    "                ax.text(0.95, 0.95, f'#{naics_code}', transform=ax.transAxes,\n",
    "                        fontsize=9, va='top', ha='right')\n",
    "                ax.set_xlim(g.str2date(start), g.int2date(200701))\n",
    "\n",
    "                # plot events\n",
    "                for evt, ls in zip(['Emergency declared', 'SAH ordered'], ['--', '-.']):\n",
    "                    date = g.str2date(c.events[evt])\n",
    "                    ax.axvline(date, color=c.color, ls=ls, lw=0.8)\n",
    "    for ax_ in axs.flatten():\n",
    "        ax_.set_ylim(0, ax_.get_ylim()[1])\n",
    "    if plot:\n",
    "        fig.text(-0.005, 0.5, 'Total CEI (1000 min/ft)',\n",
    "                 va='center', rotation='vertical', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "    return daily_exp\n",
    "    \n",
    "# fig_exp_by_nacis()\n",
    "daily_exp = fig_exp_by_nacis(dpi=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "peek(daily_exp)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "daily_exp.to_csv(g.CODE_DIR + '/daily_cei_by_city_naics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fig_exp_coverage_by_naics(daily_exp, win=1, dpi=70):\n",
    "    fig = plt.figure(figsize=(15, 8), dpi=dpi)\n",
    "    gs = mpl.gridspec.GridSpec(2, 3, width_ratios=[1, 1, 0.75])\n",
    "    for i, c in enumerate([nyc, chi]):\n",
    "        # resolve dates\n",
    "        dt_emerg = g.str2date(c.events['Emergency declared'])\n",
    "        dt_sah = g.str2date(c.events['SAH ordered'])\n",
    "        \n",
    "        # prepare the contribution data\n",
    "        df = (daily_exp.rename(columns={'tot_cei': 'cei', 'exp_visits': 'vis'})\n",
    "               .pivot(index=['city', 'date'], columns='category',\n",
    "                               values=['vis', 'cei']).reset_index('date')\n",
    "               .loc[c.name].set_index('date').rolling(win).mean())\n",
    "        # exposure distribution\n",
    "        tot_cei = df['cei'].sum(axis=1)\n",
    "        cei = df['cei'].drop(columns=['Others'])\n",
    "        pdf = cei/tot_cei.values[:, None]*100\n",
    "        \n",
    "        # avg CEI series by NAICS grouped by custom periods\n",
    "        avg_cei = df['cei'] / df['vis']\n",
    "        periods = (pd.DataFrame.from_dict(\n",
    "            {'Jan': 200131, 'Feb': 200229, 'Mar\\n(1)': 200315,\n",
    "             'Mar\\n(2)': 200331, 'Apr': 200430, 'May': 200531, 'Jun': 200630},\n",
    "            orient='index', columns=['date_int']).rename_axis('period')\n",
    "                   .assign(date = lambda x: g.int2date(x['date_int'])))\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore')\n",
    "            df['period'] = (pd.cut(df.index, [g.str2date('2019-12-31')] +\n",
    "                                        periods['date'].tolist()))\n",
    "            df['period'] = periods.index[df['period'].cat.codes]\n",
    "            grp_df = df.groupby('period').sum()\n",
    "            avg_cei = (grp_df['cei'] / grp_df['vis']).reindex(periods.index)\n",
    "        \n",
    "        # plot\n",
    "        colors = sns.color_palette('husl', 12)[::-1]\n",
    "        ax1 = plt.subplot(gs[i, 0])\n",
    "        ax2 = plt.subplot(gs[i, 1])\n",
    "        ax3 = plt.subplot(gs[i, 2])\n",
    "        \n",
    "        # total CEI before & after emergency\n",
    "        pdf[pdf.index < dt_emerg].plot.area(ax=ax1, color=colors, alpha=0.3)\n",
    "        pdf[pdf.index >= dt_emerg].plot.area(ax=ax2, color=colors, alpha=0.3)\n",
    "        for ax in [ax1, ax2]:\n",
    "            ax.get_legend().remove()\n",
    "            ax.set_xlabel('')\n",
    "            ax.set_ylabel('Percentage')\n",
    "            ax.xaxis.set_major_formatter(mpl.dates.DateFormatter('%b'))\n",
    "        ax1.axvline(dt_emerg, color='k', ls='--')\n",
    "        ax1.xaxis.set_minor_locator(mpl.dates.WeekdayLocator())\n",
    "        ax1.set_title(f'{c.name}: Before\\n emergency ({dt_emerg.strftime(\"%d %b\")})',\n",
    "                      fontsize=15, y=1.02)\n",
    "        ax2.axvline(dt_sah, color='k', ls='--')\n",
    "        ax2.text(dt_sah + pd.DateOffset(days=4), ax2.get_ylim()[1]/2,\n",
    "                 'SAH ordered ('+dt_sah.strftime('%m/%d')+')',\n",
    "                 rotation=90, va='center', ha='center')\n",
    "        ax2.set_xlim(right=g.int2date(200701))\n",
    "        ax2.set_title(f'{c.name}: After emergency ', fontsize=15, y=1.02)\n",
    "        \n",
    "        # avg CEI after emergency\n",
    "        avg_cei = avg_cei.drop(columns='Others')\n",
    "        avg_cei.plot(ax=ax3, color=colors, marker='^', lw=0.4, alpha=0.8)\n",
    "        ax3.get_legend().remove()\n",
    "        ax3.set_xlabel('')\n",
    "        ax3.set_ylabel('Avg CEI (min/ft)')\n",
    "        ax3.set_title(f'{c.name}: CEI per visit', fontsize=15, y=1.02)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore')\n",
    "            ax3.xaxis.set_major_locator(plt.MultipleLocator(1))\n",
    "            ax3.set_xticklabels([None] + avg_cei.index.tolist(), rotation=0)\n",
    "        for cat in ['Schools', 'Full Restaurants', 'Bars/Pubs', 'Hospitals']:\n",
    "            ax3.plot(avg_cei[cat], color=colors[avg_cei.columns.get_loc(cat)], lw=2)\n",
    "        ax3.text(2.4, 3.1, 'Schools', fontsize=13)\n",
    "        ax3.text(4.4, 0.8, 'Bars/Pubs', fontsize=13)\n",
    "        ax3.text(4.4, 1.7, 'Hospitals', fontsize=13)\n",
    "        ax3.plot([0.2, 0.9], [1.5, 2.3], color='k', lw=1)\n",
    "        ax3.text(0.95, 2.35, 'Restaurants', fontsize=13)\n",
    "            \n",
    "        # legend\n",
    "        if i == 1:\n",
    "            labels = pdf.columns.tolist()\n",
    "            handles = [mpl.patches.Patch(\n",
    "                facecolor=(*colors[i], 0.3), lw=2, edgecolor=colors[i])\n",
    "                       for i in range(pdf.columns.size)]\n",
    "            leg = ax3.legend(handles, labels, title='Industry', bbox_to_anchor=(2.1, 2))\n",
    "    plt.subplots_adjust(hspace=0.4, wspace=0.25)\n",
    "\n",
    "fig_exp_coverage_by_naics(daily_exp, dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for c in [nyc, chi]:\n",
    "    c.exp_od = get_odX(c, True)[['naics', 'week', 'exp_visits', 'tot_cei', 'home_zip']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nyc.pat.week.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def exp_by_naics_n_inc(dpi=70):\n",
    "    imp_wks = [200217, 200316, 200420, 200608]\n",
    "    nWk = len(imp_wks) # = 3\n",
    "    nCat = g.IMP_NAICS.shape[0] # = 12\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(13, 5), dpi=dpi, sharey=True)\n",
    "    ax = ax.flatten()\n",
    "    for i, c in enumerate([nyc, chi]):\n",
    "        df = ((c.exp_od[c.exp_od['week'].isin(imp_wks)]\n",
    "               .merge(g.IMP_NAICS['category'], on='naics')\n",
    "               .merge(c.acs_zip['hh_inc_q'], left_on='home_zip', right_index=True)\n",
    "               .groupby(['week', 'hh_inc_q', 'category'])\n",
    "               [['exp_visits', 'tot_cei']].sum()/1e3).reset_index()\n",
    "              .assign(avg_cei = lambda x: x['tot_cei']/x['exp_visits'])\n",
    "              .sort_values(['category', 'week'])\n",
    "              .astype({'category': 'category', 'week': 'category'}))\n",
    "        df['xpos'] = (nWk+1)*df['category'].cat.codes + df['week'].cat.codes + 1\n",
    "        if i == 1:\n",
    "            df = df.assign(hh_inc_q = lambda x: x.hh_inc_q.map({1:3,2:5,3:4,4:2,5:1}))\n",
    "        df['color'] = [g.COLORS['income_classes5'][x] for x in (df['hh_inc_q']-1)]\n",
    "        \n",
    "        # plot\n",
    "        for _, sub in df.groupby(['category', 'hh_inc_q']):\n",
    "            ax[i].plot(sub['xpos'], sub['tot_cei'], color=sub['color'].iloc[0],\n",
    "                       marker='.', markersize=7, lw=0.6)\n",
    "        for x in df['xpos'].unique():\n",
    "            ax[i].axvline(x, color='darkgrey', lw=0.3)\n",
    "        ax[i].set_yscale('log')\n",
    "        ax[i].set_xticks(np.arange((nWk+1)/2, (nWk+1)*nCat, nWk+1))\n",
    "        ax[i].set_xticklabels(df['category'].astype('str').unique(), rotation=90)\n",
    "        ax[i].set_title(c.name, fontsize=18)\n",
    "        if i == 0:\n",
    "            ax[i].set_ylabel('Weekly Total CEI (min/ft)')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "exp_by_naics_n_inc(dpi=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
